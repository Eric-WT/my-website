<!DOCTYPE html>
<html>

<head>
    <title>The 1st International Workshop on Multimodal Foundation Models for Spatial Intelligence</title>

    <style>
        body {
            width: 95%;
            margin: 0 auto;
            background-color: #f2f2f2;
            font-size: 18px;
            /* default 16px */
        }

        a:link {
            color: blue;
        }

        a:visited {
            color: blue;
        }

        a:hover {
            color: orange;
        }

        img {
            max-width: 100%;
            max-height: 100%;
        }

        td {
            text-align: left;
            padding-top: 5px;
            padding-bottom: 5px;
            padding-left: 15px;
            padding-right: 0px;
        }

        .row {
            content: "";
            clear: both;
            display: flex;
            flex-direction: row;
            justify-content: center;
            padding-bottom: 5px;
        }

        .column {
            float: left;
            width: 15%;
            padding: 5px;
        }

        .container {
            text-align: center;
            background-color: #ffffff;
            padding: 15px;
            margin: 20px;
        }

        .text-content {
            text-align: left;
        }

        .text-content .text-box {
            /* text-indent: 2ch; */
        }

        .text-content .table-box {
            width: 100%;
            height: 0;
            padding-bottom: 29%;
            background: url(images/table.jpg) no-repeat;
            background-size: 100% 100%;
        }

        .text-content .text-title {
            font-weight: bold;
        }

        .text-content .text-p {
            text-indent: 2ch;
            margin: 10px 0;
        }

        /* .td1 {
            padding: 0 20px 0 50px;
        } */

        @media only screen and (max-width: 768px) {
            .row {
                display: flex;
                flex-direction: column;
                justify-content: center;
            }

            .column {
                float: left;
                width: 100%;
                padding: 0px;
                margin-bottom: 10px;
            }
        }
    </style>

    <meta charset="UTF-8">
    <meta name="description" content="ECCV 2024 Tutorial on Emerging Trends in Disentanglement and Compositionality">
    <meta name="keywords" content="ECCV, Disentanglement and Compositionality, Computer Vision">
    <meta name="author" content="Xin Jin et al.">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

    <div class="container">
        <h1>The 1st International Workshop on Multimodal Foundation</h1>
        <h1>Models for Spatial Intelligence</h1>
        <img src="images/MM25.jpg" width="50%" alt="MM25">
    </div>


    <div class="container">
        <h2>Overview</h2>
        <div class="text-content">
             <p>
                Multimodal foundation models have transformed artificial intelligence by enabling scalable and transferable representations across diverse modalities, facilitating applications in vision-language understanding, text-to-image/video generation, and AI-driven assistants. However, their reliance on predominantly linguistic and 2D visual representations limits their ability to interact effectively with the physical world, where deep 3D spatial reasoning is crucial. Spatial intelligence, which encompasses perception, comprehension, and reasoning about spatial relationships and 3D structures, is essential for advancing AI models beyond static, task-specific functions toward embodied capabilities. Achieving robust spatial intelligence is critical for applications such as autonomous systems, robotics, augmented reality, and digital twins.
            </p>

             <p>
                This workshop seeks to bring together researchers and practitioners from multimedia and related communities to discuss <span style="color: #bf9000;">Multimodal Foundation Models for Spatial Intelligence</span>. There are a lot of open problems to be explored, no matter the aspects of multimedia data and benchmarks, framework designs, training techniques, or trust-worthy algorithms. By uniting insights from researchers from various backgrounds, we aim to step towards reshaping the future of spatially-aware foundation models and paving the way for next-generation AI systems capable of perceiving, reasoning, and acting in complex 3D environments.
             </p>
        </div>
    </div>

    <div class="container">
        <h2>Call for Papers</h2>

        <div class="text-content">
            <div class="text-box">
                We welcome three types of submissions, all of which should align with the topics of interest below:
            </div>
            <br>
            <div class="text-box">
                •  <span class="text-title">Position or Perspective Papers</span> (up to 4 pages, excluding references): Original ideas, perspectives, research visions, and open challenges related to evaluation approaches for explainable recommender systems.
            </div>
            <br>
            <div class="text-box">
                •  <span class="text-title">Featured Papers</span> (title, abstract, and the original paper): Previously published papers or summaries of existing publications from leading conferences and high-impact journals that are relevant to the workshop theme.
            </div>
            <br>
            <div class="text-box">
                •  <span class="text-title">Demonstration Papers</span> (up to 2 pages, excluding references): Original or previously published prototypes and operational evaluation approaches in explainable recommender systems.
            </div>

            <br><br>

            <h2>Topics of Interest</h2>
            <div class="text-box">
                We invite submissions of original research contributions related to, but not limited to, the following topics:
            </div>
            <br>

            <div class="text-box">1. <span class="text-title">Multimodal Spatial Understanding</span></div>
            <div class="text-p">•  Multimodal Large Language Models with Spatial Awareness</div>
            <div class="text-p">•  (3D) Vision-Language-Action Alignment</div>
            <div class="text-p">•  3D Scene Perception (Detection, Segmentation)</div>
            <div class="text-p">•  3D Semantic Occupancy Prediction</div>
            <div class="text-p">•  Multimodal Spatial Reasoning (Images, Videos, Point Clouds, Text, Audio, etc.)</div>
            <div class="text-p">•  3D Spatial Grounding</div>
            <div class="text-p">•  Multimodal Affordance Learning</div>

            <div class="text-box">2. <span class="text-title">3D/3D-Aware Generative Models and World Models</span></div>
            <div class="text-p">•  3D-Aware Diffusion Models and Variational Autoencoders (VAEs)</div>
            <div class="text-p">•  World Models and Its Application in Embodied AI and Autonomous Vehicles</div>
            <div class="text-p">•  3D Generative Adversarial Networks (3D GANs)</div>
            <div class="text-p">•  Multi-view Consistent 3D Generation</div>
            <div class="text-p">•  Camera View and Motion Controllability in Generation</div>

            <div class="text-box">3. <span class="text-title">3D Geometric Reconstruction</span></div>
            <div class="text-p">•  3D Reconstruction from Multimodal Inputs</div>
            <div class="text-p">•  Neural Implicit Representations for 3D Reconstruction</div>
            <div class="text-p">•  3D Gaussian Splatting for High-fidelity Scene Reconstruction</div>
            <div class="text-p">•  Integration of Geometric Priors in Deep Learning Models</div>
            <div class="text-p">•  SLAM and Semantic SLAM</div>
            <div class="text-p">•  Scalable 3D Reconstruction for Large-scale Datasets</div>

            <div class="text-box">4. <span class="text-title">Data and Benchmarks for Deep Spatial Analysis</span></div>
            <div class="text-p">•  Benchmarks for Spatial Intelligence</div>
            <div class="text-p">•  Large-scale Datasets for Multimodal Spatial Reasoning</div>
            <div class="text-p">•  Standardized Evaluation Protocols for 3D Generative Models</div>
            <div class="text-p">•  Novel Multimodal Annotation Techniques and Crowdsourced Datasets</div>
            <div class="text-p">•  Multimodal Learning for World Simulation</div>

            <div class="text-box">5. <span class="text-title">Trustworthy Spatial Intelligence</span></div>
            <div class="text-p">•  Ethical Considerations in 3D Generative Models</div>
            <div class="text-p">•  Trustworthy and Robust 3D Foundation Models</div>
            <div class="text-p">•  Fairness and Bias in 3D and Multimodal Datasets and Foundation Models</div>
        </div>
    </div>

    <div class="container">
        <h2>Schedule</h2>
        <table>
            <tr>
                <td class="td1">08:00 am - 08:50 am</td>
                <td>Poster setup</td>
            </tr>
    
            <tr>
                <td class="td1">08:50 am - 09:00 am</td>
                <td>Opening remarks</td>
            </tr>
    
            <tr>
                <td class="td1">09:00 am - 09:30 am</td>
                <td>Invited talk 1</td>
            </tr>
    
            <tr>
                <td class="td1">09:30 am - 10:00 am</td>
                <td>Invited talk 2</td>
            </tr>
    
            <tr>
                <td class="td1">10:00 am - 11:00 am</td>
                <td>Coffee break</td>
            </tr>
    
            <tr>
                <td class="td1">11:00 am - 11:30 am</td>
                <td>Invited talk 3</td>
            </tr>

            <tr>
                <td class="td1">11:30 am - 12:00 am</td>
                <td>Invited talk 4</td>
            </tr>

            <tr>
                <td></td>
                <td></td>
            </tr>
    
            <tr>
                <!-- <td rowspan="9">Afternoon session</td> -->
                <td class="td1">12:30 pm - 13:30 pm</td>
                <td>Lunch break</td>
            </tr>
    
            <tr>
                <td class="td1">13:30 pm - 14:00 pm</td>
                <td>Invited talk 4</td>
            </tr>
    
            <tr>
                <td class="td1">14:00 pm - 14:30 pm</td>
                <td>Invited talk 5</td>
            </tr>

            <tr>
                <td class="td1">14:30 pm - 15:00 pm</td>
                <td>Contributed talks</td>
            </tr>
    
            <tr>
                <td class="td1">15:00 pm - 16:00 pm</td>
                <td>ICoffee break</td>
            </tr>
    
            <tr>
                <td class="td1">16:00 pm - 16:30 pm</td>
                <td>Invited talk 6</td>
            </tr>

            <tr>
                <td class="td1">16:30 pm - 17:30 pm</td>
                <td>Panel</td>
            </tr>
    
            <tr>
                <td class="td1">17:30 pm - 17:40 pm</td>
                <td>Closing remarks</td>
            </tr>

            <tr>
                <td class="td1">17:40 pm - 19:00 pm</td>
                <td>Socials</td>
            </tr>
    
        </table>
    </div>


    <div class="container">
        <h2>Organizers</h2>

        <div class="row">
            <div class="column">
                <a href="https://djiajunustc.github.io/">
                    <img src="images/djj.jpg" alt="Jiajun Deng" width="220" height="230">
                    <div>Jiajun Deng<br>The University of Adelaide<br>Adelaide, Australia<br>jiajun.deng@adelaide.edu.au
                    </div>
                </a>
            </div>
            <div class="column">
                <a href="https://llijiang.github.io/">
                    <img src="images/jl.png" alt="Li Jiang" width="220" height="230">
                    <div>Li Jiang<br>CUHK (Shenzhen)<br>Shenzhen, China<br>jiangli@cuhk.edu.cn</div>
                </a>
            </div>
            <div class="column">
                <a href="https://www.eitech.edu.cn/?tid=49&p=teacher&lang=en">
                    <img src="images/jx.jpg" alt="Xin Jin" width="220" height="230">
                    <div>Xin Jin<br>Eastern Institute of Technology<br>Ningbo, China<br>jinxin@eitech.edu.cn</div>
                </a>
            </div>
            <div class="column">
                <a href="https://www.microsoft.com/en-us/research/people/tianyuhe/">
                    <img src="images/hty.jpg" alt="Tianyu He" width="220" height="230">
                    <div>Tianyu He<br>Microsoft<br>Beijing, China<br>tianyuhe@microsoft.com</div>
                </a>
            </div>
            <div class="column">
                <a href="https://zhengyuan.info/">
                    <img src="images/yzy.jpg" alt="Zhengyuan Yang" width="220" height="230">
                    <div>Zhengyuan Yang<br>Microsoft<br>Seattle, USA<br>zhengyuan.yang13@gmail.com</div>
                </a>
            </div>
        </div>

        <div class="row">
            <div class="column">
                <a href="http://staff.ustc.edu.cn/~zhwg/">
                    <img src="images/zwg.png" alt="Wengang Zhou" width="220" height="230">
                    <div>Wengang Zhou<br>USTC<br>Hefei, China<br>zhwg@ustc.edu.cn</div>
                </a>
            </div>
            <div class="column">
                <a href="https://scholar.google.com.au/citations?user=RMSuNFwAAAAJ&hl=en">
                    <img src="images/yy.png" alt="Yi Yang" width="220" height="230">
                    <div>Yi Yang<br>Zhejiang University<br>Hangzhou, China<br>yangyics@zju.edu.cn</div>
                </a>
            </div>
            <div class="column">
                <a href="https://disi.unitn.it/~sebe/">
                    <img src="images/NicuSebe.png" alt="Nicu Sebe" width="220" height="230">
                    <div>Nicu Sebe<br>University of Trento<br>Trento, Italy<br>sebe@disi.unitn.it</div>
                </a>
            </div>
            <div class="column">
                <a href="http://staff.ustc.edu.cn/~lihq/en/">
                    <img src="images/lhq.jpg" alt="Houqiang Li" width="220" height="230">
                    <div>Houqiang Li<br>USTC<br>Hefei, China<br>lihq@ustc.edu.cn</div>
                </a>
            </div>
        </div>
    </div>

    
    <div class="container">
        <h2>Invited Speakers</h2>
    </div>
    
    
    <div class="container">
        <h2>Contact</h2>
        <div class="text-content">
            <p>Please contact <a href="#">djiajun1206@gmail.com</a> for general inquiries.</p>
        </div>
    </div>

</body>

</html>
